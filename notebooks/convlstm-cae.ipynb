{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "version": "3.6.4",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "name": "python",
   "mimetype": "text/x-python"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import re\n",
    "import gc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchinfo import summary\n",
    "\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "execution": {
     "iopub.status.busy": "2023-04-04T16:43:07.365616Z",
     "iopub.execute_input": "2023-04-04T16:43:07.366060Z",
     "iopub.status.idle": "2023-04-04T16:43:10.057210Z",
     "shell.execute_reply.started": "2023-04-04T16:43:07.366017Z",
     "shell.execute_reply": "2023-04-04T16:43:10.056141Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Loading"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "class SkyDataset(Dataset):\n",
    "    def __init__(self, train_dir, gt_dir):\n",
    "        self.train_root = train_dir\n",
    "        self.gt_root = gt_dir\n",
    "        self.train_dirs = sorted(os.listdir(train_dir))\n",
    "        self.gt_dirs = sorted(os.listdir(gt_dir))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.train_dirs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        train_seq = torch.stack([read_image(os.path.join(self.train_root, self.train_dirs[idx], x))/255.0 for x in sorted(os.listdir(os.path.join(self.train_root, self.train_dirs[idx])))])\n",
    "        gt_seq = torch.stack([read_image(os.path.join(self.gt_root, self.gt_dirs[idx], x))/255.0 for x in sorted(os.listdir(os.path.join(self.gt_root, self.gt_dirs[idx])))])\n",
    "        return train_seq, gt_seq\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-04T16:43:10.059312Z",
     "iopub.execute_input": "2023-04-04T16:43:10.059931Z",
     "iopub.status.idle": "2023-04-04T16:43:10.068993Z",
     "shell.execute_reply.started": "2023-04-04T16:43:10.059891Z",
     "shell.execute_reply": "2023-04-04T16:43:10.067837Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "input_dir = '../SkyDataset/train'\n",
    "gt_dir = '../SkyDataset/gt'\n",
    "train_set = SkyDataset(input_dir, gt_dir)\n",
    "train_dataloader = DataLoader(train_set, batch_size=2, shuffle=True)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-04T16:43:10.070560Z",
     "iopub.execute_input": "2023-04-04T16:43:10.071236Z",
     "iopub.status.idle": "2023-04-04T16:43:10.371129Z",
     "shell.execute_reply.started": "2023-04-04T16:43:10.071198Z",
     "shell.execute_reply": "2023-04-04T16:43:10.370146Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch.set_default_device(device)\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-04T16:43:10.383319Z",
     "iopub.execute_input": "2023-04-04T16:43:10.383729Z",
     "iopub.status.idle": "2023-04-04T16:43:10.507160Z",
     "shell.execute_reply.started": "2023-04-04T16:43:10.383687Z",
     "shell.execute_reply": "2023-04-04T16:43:10.505984Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Construction"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "class MotionEncoder(nn.Module):\n",
    "    def __init__(self, in_c=2, out_c=8):\n",
    "        super(MotionEncoder, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(in_c, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=8, stride=8, padding=0),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        if in_c > 2:\n",
    "            in_dim = 2560\n",
    "        else:\n",
    "            in_dim = 256\n",
    "        self.fc = nn.Linear(in_dim, out_c) # latent\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_c = self.conv_layers(x)\n",
    "        x_flatten = x_c.view(x.size(0), -1)\n",
    "        out = self.fc(x_flatten)\n",
    "        return out"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-04T16:43:10.508982Z",
     "iopub.execute_input": "2023-04-04T16:43:10.509615Z",
     "iopub.status.idle": "2023-04-04T16:43:10.521251Z",
     "shell.execute_reply.started": "2023-04-04T16:43:10.509579Z",
     "shell.execute_reply": "2023-04-04T16:43:10.520090Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class ConvLSTMCell(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, kernel_size):\n",
    "        super(ConvLSTMCell, self).__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = kernel_size // 2\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels=self.input_dim + self.hidden_dim,\n",
    "                              out_channels=4*self.hidden_dim,\n",
    "                              kernel_size=self.kernel_size,\n",
    "                              padding=self.padding)\n",
    "\n",
    "    def forward(self, input_tensor, cur_state):\n",
    "        h_cur, c_cur = cur_state\n",
    "        combined = torch.cat([input_tensor, h_cur], dim=1)\n",
    "\n",
    "        combined_conv = self.conv(combined)\n",
    "        cc_i, cc_f, cc_o, cc_g = torch.split(combined_conv, self.hidden_dim, dim=1)\n",
    "        i = torch.sigmoid(cc_i)\n",
    "        f = torch.sigmoid(cc_f)\n",
    "        o = torch.sigmoid(cc_o)\n",
    "        g = torch.tanh(cc_g)\n",
    "\n",
    "        c_next = f * c_cur + i * g\n",
    "        h_next = o * torch.tanh(c_next)\n",
    "        return h_next, c_next\n",
    "\n",
    "    def init_hidden(self, batch_size, image_size):\n",
    "        height, width = image_size\n",
    "        return (torch.zeros(batch_size, self.hidden_dim, height, width),\n",
    "                torch.zeros(batch_size, self.hidden_dim, height, width))\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-04T16:43:10.539846Z",
     "iopub.execute_input": "2023-04-04T16:43:10.540242Z",
     "iopub.status.idle": "2023-04-04T16:43:10.553280Z",
     "shell.execute_reply.started": "2023-04-04T16:43:10.540206Z",
     "shell.execute_reply": "2023-04-04T16:43:10.552336Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class CAE(nn.Module):\n",
    "    def __init__(self, nf, in_chan):\n",
    "        super(CAE, self).__init__()\n",
    "        self.nf = nf\n",
    "        self.e1 = ConvLSTMCell(input_dim=in_chan, hidden_dim=nf, kernel_size=3)\n",
    "        self.e2 = ConvLSTMCell(input_dim=nf, hidden_dim=nf, kernel_size=3)\n",
    "        self.d1 = ConvLSTMCell(input_dim=nf,hidden_dim=nf, kernel_size=3)\n",
    "        self.d2 = ConvLSTMCell(input_dim=nf,hidden_dim=nf,kernel_size=3)\n",
    "        self.d3 = nn.Conv3d(in_channels=nf, out_channels=3, kernel_size=3,padding=1)\n",
    "\n",
    "    def autoencoder(self, x, seq_len, future_step, h_t, c_t, h_t2, c_t2, h_t3, c_t3, h_t4, c_t4):\n",
    "        outputs = []\n",
    "        for t in range(seq_len):\n",
    "            h_t, c_t = self.e1(input_tensor=x[:, t, :, :], cur_state=[h_t, c_t])\n",
    "            h_t2, c_t2 = self.e2(input_tensor=h_t, cur_state=[h_t2, c_t2])\n",
    "        \n",
    "        for t in range(future_step):\n",
    "            h_t3, c_t3 = self.d1(input_tensor=h_t2, cur_state=[h_t3, c_t3])\n",
    "            h_t4, c_t4 = self.d2(input_tensor=h_t3, cur_state=[h_t4, c_t4])\n",
    "            outputs += [h_t4]\n",
    "        \n",
    "        outputs = torch.stack(outputs, 1)\n",
    "        outputs = outputs.permute(0, 2, 1, 3, 4)\n",
    "        outputs = self.d3(outputs)\n",
    "        outputs = torch.nn.Sigmoid()(outputs)\n",
    "        return outputs\n",
    "\n",
    "    def forward(self, x, future_seq=10):\n",
    "        b, seq_len, c, h, w = x.size()\n",
    "\n",
    "        h_t, c_t = self.e1.init_hidden(batch_size=b, image_size=(h, w))\n",
    "        h_t2, c_t2 = self.e2.init_hidden(batch_size=b, image_size=(h, w))\n",
    "        h_t3, c_t3 = self.d1.init_hidden(batch_size=b, image_size=(h, w))\n",
    "        h_t4, c_t4 = self.d2.init_hidden(batch_size=b, image_size=(h, w))\n",
    "\n",
    "        outputs = self.autoencoder(x, seq_len, future_seq, h_t, c_t, h_t2, c_t2, h_t3, c_t3, h_t4, c_t4)\n",
    "        return outputs"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-04T16:43:10.555010Z",
     "iopub.execute_input": "2023-04-04T16:43:10.555492Z",
     "iopub.status.idle": "2023-04-04T16:43:10.572936Z",
     "shell.execute_reply.started": "2023-04-04T16:43:10.555454Z",
     "shell.execute_reply": "2023-04-04T16:43:10.571862Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from torchvision.models.optical_flow import raft_small, Raft_Small_Weights\n",
    "from torchvision.utils import flow_to_image\n",
    "from torchvision import transforms\n",
    "\n",
    "weights = Raft_Small_Weights.DEFAULT\n",
    "flow_model = raft_small(weights=Raft_Small_Weights.DEFAULT, progress=False).to(device)\n",
    "flow_model = flow_model.eval()\n",
    "flow_tf = weights.transforms()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-04T16:43:10.577193Z",
     "iopub.execute_input": "2023-04-04T16:43:10.577483Z",
     "iopub.status.idle": "2023-04-04T16:43:14.472756Z",
     "shell.execute_reply.started": "2023-04-04T16:43:10.577443Z",
     "shell.execute_reply": "2023-04-04T16:43:14.471610Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Hyperparams"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "lr=1e-4\n",
    "num_epochs=800\n",
    "img_w = 640\n",
    "img_h = 360"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-04T16:43:14.481963Z",
     "iopub.execute_input": "2023-04-04T16:43:14.482429Z",
     "iopub.status.idle": "2023-04-04T16:43:14.492147Z",
     "shell.execute_reply.started": "2023-04-04T16:43:14.482391Z",
     "shell.execute_reply": "2023-04-04T16:43:14.491192Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def train_net(me, cae, optim_me, optim_cae):\n",
    "    criterion = nn.MSELoss()\n",
    "    train_loss = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for inputs, gts in train_dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            gts = gts.to(device)\n",
    "            \n",
    "            # find flow\n",
    "            b1 = inputs[:, 0]\n",
    "            b2 = inputs[:, 1]\n",
    "            b1, b2 = flow_tf(b1, b2)\n",
    "            flow = torch.stack(flow_model(b1, b2))\n",
    "            flow = flow[-1, :]\n",
    "            flow = F.interpolate(flow, size=(128,128), mode='bilinear', align_corners=True)\n",
    "            z = me(flow)\n",
    "\n",
    "            # stack\n",
    "            z_matched = z.view(z.size(0),1, z.size(1), 1, 1).expand(inputs.size(0), inputs.size(1), z.size(1), inputs[0].size(2), inputs[0].size(3))      \n",
    "            inputs = torch.cat((inputs, z_matched), 2)\n",
    "            \n",
    "            # prediction\n",
    "            preds = cae(inputs).permute(0, 2, 1, 3, 4)\n",
    "            optim_me.zero_grad()\n",
    "            optim_cae.zero_grad()\n",
    "\n",
    "            loss = criterion(preds, gts)\n",
    "            loss += criterion((preds[:, -1] - preds[:, 0]).detach(), (gts[:, -1] - gts[:, 0]).detach())\n",
    "\n",
    "            loss.backward()\n",
    "            optim_me.step()\n",
    "            optim_cae.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "\n",
    "        train_loss.append(float(total_loss) / len(train_dataloader))\n",
    "        print(\"Epoch {}: Train loss: {}\". format(epoch + 1, train_loss[epoch]))\n",
    "\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'me': me.state_dict(),\n",
    "            'cae': cae.state_dict(),\n",
    "            'optim_me': optim_me.state_dict(),\n",
    "            'optim_cae': optim_cae.state_dict()\n",
    "            }, \n",
    "            f'/kaggle/working/checkpoint_cae_{epoch}.pt')\n",
    "        np.savetxt(f'loss_{epoch}.txt', train_loss)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-04T16:43:14.505690Z",
     "iopub.execute_input": "2023-04-04T16:43:14.506514Z",
     "iopub.status.idle": "2023-04-04T16:43:14.522821Z",
     "shell.execute_reply.started": "2023-04-04T16:43:14.506476Z",
     "shell.execute_reply": "2023-04-04T16:43:14.521799Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "me = MotionEncoder()\n",
    "me = me.to(device)\n",
    "cae = CAE(nf = 22, in_chan = 11)\n",
    "cae = cae.to(device)\n",
    "\n",
    "optim_me = Adam(me.parameters(), lr=1e-4)\n",
    "optim_cae = Adam(cae.parameters(), lr=1e-4)\n",
    "\n",
    "checkpoint = torch.load('checkpoints/checkpoint_cae_302.pt')\n",
    "me.load_state_dict(checkpoint['me'])\n",
    "cae.load_state_dict(checkpoint['cvae'])  # checkpoints contain a mistake in naming here\n",
    "optim_me.load_state_dict(checkpoint['optim_me'])\n",
    "optim_cae.load_state_dict(checkpoint['optim_cvae'])"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-04T16:43:14.524503Z",
     "iopub.execute_input": "2023-04-04T16:43:14.524943Z",
     "iopub.status.idle": "2023-04-04T16:43:15.371023Z",
     "shell.execute_reply.started": "2023-04-04T16:43:14.524903Z",
     "shell.execute_reply": "2023-04-04T16:43:15.369862Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "torch.cuda.empty_cache()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-04T16:43:15.372535Z",
     "iopub.execute_input": "2023-04-04T16:43:15.372968Z",
     "iopub.status.idle": "2023-04-04T16:43:15.381034Z",
     "shell.execute_reply.started": "2023-04-04T16:43:15.372928Z",
     "shell.execute_reply": "2023-04-04T16:43:15.380117Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_net(me, cae, optim_me, optim_cae)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-04T16:43:15.382554Z",
     "iopub.execute_input": "2023-04-04T16:43:15.383458Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
